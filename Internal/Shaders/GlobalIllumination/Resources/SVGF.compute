// Each #kernel tells which function to compile; you can have many kernels
#pragma kernel SVGFKernel
#pragma kernel StoreToPreviousBuffer
#pragma kernel Atorus

// Create a RenderTexture with enableRandomWrite flag and set it
// with cs.SetTexture
Texture2D<float4> _CameraMotionVectorsTexture;
Texture2D<float4> _UnigmaGlobalIllumination;
Texture2D<float4> _UnigmaCameraDepthTexture;

RWTexture2D<float4> _UnigmaDenoisedGlobalIllumination;
Texture2D<float4> _UnigmaAlbedo;
Texture2D<float4> _UnigmaNormal;
Texture2D<float4> _UnigmaMotionID;

//Temporal buffers.
RWTexture2D<float4> _UnigmaDenoisedGlobalIlluminationTemporal;
RWTexture2D<float4> _UnigmaDenoisedGlobalIlluminationTemp;
RWTexture2D<float4> _UnigmaAlbedoTemporal;
RWTexture2D<float4> _UnigmaNormalTemporal;
RWTexture2D<float4> _UnigmaMotionIDTemporal;

struct SVGF
{
	float history;
	float2 moments;
};

RWStructuredBuffer<SVGF> _SVGFBuffer;


float _PLANE_DISTANCE_THRESHOLD = 0.01;
float _NORMAL_DISTANCE_THRESHOLD = 0.01;
int _StepSize = 1;

float luminance(float3 color)
{
	return (color.r * 0.3) + (color.g * 0.59) + (color.b * 0.11);
}

bool CheckNormalSimilarity(float3 currentNormal, float3 prevNormal)
{
	if (pow(abs(dot(currentNormal, prevNormal)), 1) < 0.02)
		return false;
	else
		return true;
}

bool CheckPlane(float3 currentPos, float3 prevPos, float3 currentNormal)
{
	float3 toCurrent = currentPos - prevPos;
	float distToPlane = abs(dot(toCurrent, currentNormal));

	return distToPlane < 0.00051;
	
}

bool CheckReprojection(float2 UV, float2 prevUV)
{
	bool planeCheck = CheckPlane(_UnigmaMotionID[UV].xyz, _UnigmaMotionIDTemporal[UV].xyz, _UnigmaNormal[UV].xyz);
	
	bool normalCheck = CheckNormalSimilarity(_UnigmaNormal[UV].xyz, _UnigmaNormalTemporal[prevUV].xyz);

	bool pdfCheck = abs(_UnigmaDenoisedGlobalIllumination[UV].a - _UnigmaDenoisedGlobalIlluminationTemporal[UV].a) < 0.01;
	
	return normalCheck && planeCheck && pdfCheck;
}

bool IsNaN(float x)
{
	uint exponent = (asuint(x) & 0x7f800000) >> 23;
	uint mantissa = (asuint(x)) & 0x7fffff;
	return exponent == 0xff && mantissa != 0;
}

float ComputeVariance(int2 ipos)
{
	float sum = 0.f;

	const float kernel[2][2] = {
		{ 1.0 / 4.0, 1.0 / 8.0 },
		{ 1.0 / 8.0, 1.0 / 16.0 },
	};

	const int radius = 1;
	for (int yy = -radius; yy <= radius; yy++)
	{
		for (int xx = -radius; xx <= radius; xx++)
		{
			const int2 p = ipos + int2(xx, yy);
			const float k = kernel[abs(xx)][abs(yy)];
			sum += _UnigmaDenoisedGlobalIllumination[ipos].a * k;
		}
	}

	return sum;
}

float NormalEdgeWeight(float3 centerNormal, float3 sampleNormal, float power)
{
	return pow(clamp(dot(centerNormal, sampleNormal), 0.0f, 1.0f), power);
}

float DepthEdgeWeight(float centerDepth, float sampleDepth, float phi)
{
	return exp(-abs(centerDepth - sampleDepth) / phi);
}

float LumaEdgeWeight(float centerLuma, float sampleLuma, float phi)
{
	return abs(centerLuma - sampleLuma) / phi;
}

[numthreads(8,8,1)]
void SVGFKernel(uint3 id : SV_DispatchThreadID)
{
	uint dimensionsWidth, dimensionsHeight;
	
	_CameraMotionVectorsTexture.GetDimensions(dimensionsWidth, dimensionsHeight);
	uint2 dim = uint2(dimensionsWidth, dimensionsHeight);
	
	if (id.x >= dim.x || id.y >= dim.y)
		return;

	//Get current sample.
	float4 currentSample = _UnigmaGlobalIllumination[id.xy];

	//Get motion vectors
	float4 motionVector = _CameraMotionVectorsTexture[id.xy];
	float2 UV = ((id.xy + float2(0.5, 0.5)) / float2(dim.x, dim.y)) * 2 - 1;
	float2 invPrevUV = UV - motionVector.xy;
	
	float2 previousFrameIndex = ((invPrevUV * dim.xy + dim.xy) / 2) - 0.5f;
	int previousFrameIndedFlatten = previousFrameIndex.x + previousFrameIndex.y * dim.x;
	
	float4 output = currentSample;
	
	float historyLength = 1.0f;
	int flattenIndex = id.x + id.y * dim.x;
	float variance = 1.0;

	if (distance(invPrevUV, UV) > 0.00001)
	{
		_SVGFBuffer[previousFrameIndedFlatten].history *= 0.05;
	}
	
	if (CheckReprojection(id.xy, previousFrameIndex))
	{
		float4 prevSample = _UnigmaDenoisedGlobalIlluminationTemporal[previousFrameIndex];
		historyLength = _SVGFBuffer[previousFrameIndedFlatten].history += 1;
		
		float alpha = 1.0f / historyLength;

		float2 moments = 0;
		moments.r = luminance(currentSample.xyz);
		moments.g = moments.r * moments.r;

		float2 historyMoment = _SVGFBuffer[previousFrameIndedFlatten].moments;
		
		
		moments = lerp(historyMoment, moments, alpha);
		variance = max(0.0f, moments.g - moments.r * moments.r);
		
		output = lerp(prevSample, currentSample, alpha);
		output.a = variance;
		
		_SVGFBuffer[flattenIndex].history = historyLength;
		_SVGFBuffer[previousFrameIndedFlatten].moments = moments;
	}
	else
	{
		_SVGFBuffer[previousFrameIndedFlatten].history = 0;
	}

	float3 currentNormal = _UnigmaNormal[id.xy].xyz; 
	float3 prevNormal = _UnigmaNormalTemporal[previousFrameIndex].xyz;

	float normalDiff = pow(abs(dot(currentNormal, prevNormal)), 0.1);

	//_UnigmaMotionID[UV].xyz, _UnigmaMotionIDTemporal[prevUV].xyz, _UnigmaNormal[UV].xyz
	float3 toCurrent = _UnigmaMotionID[id.xy].xyz - _UnigmaMotionIDTemporal[id.xy].xyz;
	float distToPlane = abs(dot(toCurrent, _UnigmaNormal[UV].xyz));

	_UnigmaDenoisedGlobalIllumination[id.xy] = output;//distToPlane;//normalDiff;//_UnigmaGlobalIllumination[id.xy];// + _UnigmaDenoisedGlobalIlluminationTemporal[id.xy] *0.5;
	
}

[numthreads(8, 8, 1)]
void StoreToPreviousBuffer(uint3 id : SV_DispatchThreadID)
{
    _UnigmaAlbedoTemporal[id.xy] = _UnigmaAlbedo[id.xy];
	_UnigmaNormalTemporal[id.xy] = _UnigmaNormal[id.xy];
	_UnigmaMotionIDTemporal[id.xy] = _UnigmaMotionID[id.xy];
	_UnigmaDenoisedGlobalIlluminationTemporal[id.xy] = _UnigmaDenoisedGlobalIllumination[id.xy];
	_UnigmaDenoisedGlobalIllumination[id.xy] = _UnigmaDenoisedGlobalIlluminationTemp[id.xy];
}

[numthreads(8, 8, 1)]
void Atorus(uint3 id : SV_DispatchThreadID)
{
	uint dimensionsWidth, dimensionsHeight;

	_CameraMotionVectorsTexture.GetDimensions(dimensionsWidth, dimensionsHeight);
	uint2 dim = uint2(dimensionsWidth, dimensionsHeight);

	if (id.x >= dim.x || id.y >= dim.y)
		return;

	//Get current sample.
	float4 currentSample = _UnigmaDenoisedGlobalIllumination[id.xy];

	//Get motion vectors
	float4 motionVector = _CameraMotionVectorsTexture[id.xy];
	float2 UV = ((id.xy + float2(0.5, 0.5)) / float2(dim.x, dim.y)) * 2 - 1;
	float2 invPrevUV = UV - motionVector.xy;

	float2 previousFrameIndex = ((invPrevUV * dim.xy + dim.xy) / 2) - 0.5f;
	int previousFrameIndedFlatten = previousFrameIndex.x + previousFrameIndex.y * dim.x;
	
	int flattenIndex = id.x + id.y * dim.x;
	float historyLength = _SVGFBuffer[flattenIndex].history;
	
	//A torus filter.
	float sumWeights = 0.0;
	float4 sum = 0.0;
	float variance = _UnigmaDenoisedGlobalIllumination[id.xy].a;
	float sumVariance = variance;

	
	int _KernelSize = 2;
	const float kernelWeights[4] = { 1.0, 2.0 / 3.0, 1.0 / 6.0, 1.0 / 9.0 };

	float3 centerNormal = _UnigmaNormal[id.xy].xyz;
	float centerDepth = _UnigmaCameraDepthTexture[id.xy];

	for (int yy = -_KernelSize; yy <= _KernelSize; yy++)
	{
		for (int xx = -_KernelSize; xx <= _KernelSize; xx++)
		{
			float2 offset = float2(xx, yy);
			float2 sampleUV = id.xy + offset * _StepSize;

			if (sampleUV.x < 0 || sampleUV.x >= dim.x || sampleUV.y < 0 || sampleUV.y >= dim.y)
				continue;

			float4 sampleNoise = _UnigmaDenoisedGlobalIllumination[sampleUV];
			float4 sampleColor = _UnigmaAlbedo[sampleUV];
			float3 sampleNormal = _UnigmaNormal[sampleUV].xyz;
			float sampleVariance = ComputeVariance(sampleUV);
			float sampleDepth = _UnigmaCameraDepthTexture[sampleUV];

			float phiColor = 10.0f * sqrt(max(0.0, 0.0000001 + sampleVariance));
			
			float normalPhi = NormalEdgeWeight(centerNormal, sampleNormal, 0.01);
			float depthPhi = DepthEdgeWeight(centerDepth, sampleDepth, phiColor);
			float colorPhi = LumaEdgeWeight(luminance(_UnigmaAlbedo[id.xy]).r, luminance(sampleColor).r, phiColor);
			
			float weight = exp(-colorPhi - depthPhi - normalPhi);
			weight *= kernelWeights[abs(xx)] * kernelWeights[abs(yy)];

			// Variance-based weighting
			float varianceWeight = 1.0 / (1.0 + max(0.0, sampleVariance - variance));
			weight *= varianceWeight;

			sumWeights += weight;
			sum += sampleNoise * weight;
			sumVariance += sampleVariance * weight;
		}
	}
	//Is UnigmaGlobal Illumination NAN in any component
	float nan = IsNaN(_UnigmaGlobalIllumination[id.xy].x) + IsNaN(_UnigmaGlobalIllumination[id.xy].y) + IsNaN(_UnigmaGlobalIllumination[id.xy].z) + IsNaN(_UnigmaGlobalIllumination[id.xy].w);
	_UnigmaDenoisedGlobalIlluminationTemp[id.xy] = sum / sumWeights;

}