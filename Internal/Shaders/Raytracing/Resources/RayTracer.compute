// Each #kernel tells which function to compile; you can have many kernels
#pragma kernel RayTrace
#include "../../ShaderHelpers.hlsl"

RWTexture2D<float4> _RayTracer;
float4x4 _CameraToWorld;
float4x4 _CameraInverseProjection;
Texture2D<float4> _SkyBoxTexture;
SamplerState sampler_SkyBoxTexture;
float epsilon = 0.00001;

struct Ray
{
	float3 o;
	float3 d;
	float2 os; //pixel screen space.
	float3 energy;
};

struct Hit
{
	float3 position;
	float distance;
	float3 normal;
	float3 color;
};

struct MeshObject
{
	float4x4 localToWorld;
	int indicesOffset;
	int indicesCount;
};

struct Vertex
{
	float3 position;
	float3 normal;
	float2 uv;
};

StructuredBuffer<MeshObject> _MeshObjects;
StructuredBuffer<Vertex> _Vertices;
StructuredBuffer<int> _Indices;

Ray CreateRay(float3 og, float3 dir, float2 pixel)
{
	Ray ray;
	ray.o = og;
	ray.d = dir;
	ray.os = pixel;
	ray.energy = float3(1, 1, 1);
	return ray;
}

Ray CreateCameraRay(float2 uv)
{
	//Get the world position of the origin, which is basically just the camera.
	// Last column contains position, take that.
	float3 og = mul(_CameraToWorld, float4(0, 0, 0, 1)).xyz;

	//The scene has a depth to it. The project matrix takes the depth and places it flat onto a 2D plane.
	//The inverse projection does this process backwards. By multiplying it we go backwards.
	float3 dir = mul(_CameraInverseProjection, float4(uv, -1, 1)).xyz;
	dir = mul(_CameraToWorld, float4(dir, 0)).xyz; //Take this 3D pixel point and make it world position.
	dir = normalize(dir);
	return CreateRay(og, dir, uv);
}

float4 SampleSkyBox(in Ray ray)
{
	float3 dir = normalize(ray.d);
	float u = 0.5 + atan2(dir.z, dir.x) / (2 * UNITY_PI);
	float v = 0.5 - asin(-dir.y) / UNITY_PI;
	return _SkyBoxTexture.SampleLevel(sampler_SkyBoxTexture, float2(u, v), 0);
}

Hit Shade(inout Hit hit, inout Ray ray, float3 normal)
{
	float3 lightDir = normalize(_WorldSpaceLightPos0);
	float NdotL = clamp(dot(normal, lightDir), 0.0825, 1.0);
	hit.color = NdotL * _LightColor0.xyz;
	return hit;
}

float3 Reflection(inout Ray ray, inout Hit hit)
{
	if (hit.distance < 149)
	{
		float3 spec = float3(0.6, 0.6, 0.6);
		ray.o = hit.position + hit.normal * 0.001;
		
		ray.d = reflect(ray.d, hit.normal);
		ray.energy *= spec;
		hit.distance = 9999999;
		//hit.normal = 999999999;
		hit.color *= ray.energy;
		return 1;
	}
	else
	{
		hit.color = SampleSkyBox(ray).xyz*ray.energy;
		ray.energy = 0;
		return SampleSkyBox(ray).xyz;
	}
}


void IntersectPlane(inout Hit hit, in Ray ray, float3 a, float3 b, float3 c)
{

	float3 n = GetTriangleNormal(a, b, c);

	float3 center = GetTriangleCenter(a, b, c);
	float t = dot(center - ray.o, n) / dot(ray.d, n);
	if (t > epsilon && t < hit.distance)
	{
		hit.normal = n;
		hit.distance = t;
		hit.position = ray.o + t * ray.d;
		Shade(hit, ray, n);
		hit.color *= 20/t;
	}
}

//Moller method.
bool TriangleTrace(Ray ray, float3 a, float3 b, float3 c, inout float t, inout float u, inout float v)
{
	float3 edge1 = b - a;
	float3 edge2 = c - a;
	
	float3 pvec = cross(ray.d, edge2);
	
	float determinate = dot(edge1, pvec);

	if (determinate < epsilon)
		return false;
	
	float3 tvec = ray.o - a;
	float inv_det = 1.0 / determinate;
	
	u = dot(tvec, pvec) * inv_det;
	if (u < 0.0 || u > 1.0)
	{
		return false;
	}
	
	float3 qvec = cross(tvec, edge1);
	v = dot(ray.d, qvec) * inv_det;
	if (v < 0.0 || u + v > 1.0)
	{
		return false;
	}

	//Final calculate of T after crammer's rule.
	t = dot(edge2, qvec) * inv_det;
	
	return true;
}

Hit IntersectSphere(inout Hit hit, in Ray ray, float radius, float3 center)
{
	//Quadratic formula.
	float a = dot(ray.d, ray.d);
	float b = 2 * dot((ray.o - center), ray.d);
	float c = dot(ray.o - center, ray.o - center) - radius * radius;
	float d = b * b - 4 * a * c;

	float t1 = (-b + sqrt(b * b - 4 * a * c) / 2 * a);
	float t2 = (-b - sqrt(b * b - 4 * a * c) / 2 * a);

	if(d < 0)
		return hit;
	if (t1 > epsilon && t1 < hit.distance && t1 < t2)
	{
		hit.position = ray.o + t1 * ray.d;

		float3 n = GetSphereNormal(hit.position, radius);
		hit.normal = n;
		hit.distance = t1;
		Shade(hit, ray, n);
		return hit;
	}
	else if (t2 > epsilon && t2 < hit.distance && t2 < t1)
	{
		hit.position = ray.o + t2 * ray.d;
		float3 n = GetSphereNormal(hit.position, radius);
		hit.normal = n;
		hit.distance = t2;
		Shade(hit, ray, n);
	}
	return hit;
}

void Trace(inout Ray ray, inout Hit hit)
{
	float3 a = float3(1, -3, 0);
	float3 b = float3(-1, -3, 0);
	float3 c = float3(0,-3,0.5);
	
	float3 center = float3(0, 0, 0);
	IntersectPlane(hit, ray, a, b, c);
	IntersectSphere(hit, ray, 1, center);
	for (int i = -5; i < 5; i++)
	{
		for (int j = -5; j < 5; j++)
		{
			float3 center = float3(i*2, 0, j*2);
			IntersectPlane(hit, ray, a, b, c);
			IntersectSphere(hit, ray, 1, center);
		}
	}
}

void ExecuteShadingFunction(inout Ray ray, inout Hit hit, float t, float2 tUV, Vertex v0, Vertex v1, Vertex v2, float3 PointPosition, MeshObject meshObject)
{
	hit.distance = t;
	hit.position = ray.o + t * ray.d;
	//hit.normal = normalize(cross(v1 - v0, v2 - v0));
	//Convert to world space along with ray and compute the bary centric coordinate.
	v0.position = (mul(meshObject.localToWorld, float4(v0.position, 1))).xyz;
	v1.position = (mul(meshObject.localToWorld, float4(v1.position, 1))).xyz;
	v2.position = (mul(meshObject.localToWorld, float4(v2.position, 1))).xyz;
	float3 barycentric = Barycentric(v0.position, v1.position, v2.position, hit.position);

	//Now that we have the barycentric coordinate we can use this to reconstruct the UVs.
	float2 uvs = v0.uv * barycentric.x + v1.uv * barycentric.y + v2.uv * barycentric.z;

	hit.color = float3(uvs,1);
}

void TraceMesh(inout Ray ray, inout Hit hit, MeshObject meshObject)
{
	uint offset = meshObject.indicesOffset;
	uint count = offset + meshObject.indicesCount;

	for (uint i = offset; i < count; i += 3)
	{
		float3 v0 = (mul(meshObject.localToWorld, float4(_Vertices[_Indices[i]].position, 1))).xyz;
		float3 v1 = (mul(meshObject.localToWorld, float4(_Vertices[_Indices[i + 1]].position, 1))).xyz;
		float3 v2 = (mul(meshObject.localToWorld, float4(_Vertices[_Indices[i + 2]].position, 1))).xyz;
		
		float t, u, v;
		if (TriangleTrace(ray, v0, v1, v2, t, u, v))
		{
			if (t > 0 && t < hit.distance)
			{
				float3 PointPosition = (mul(meshObject.localToWorld, float4(ray.o + t * ray.d, 1))).xyz;
				ExecuteShadingFunction(ray, hit, t, float2(u, v), _Vertices[_Indices[i]], _Vertices[_Indices[i + 1]], _Vertices[_Indices[i + 2]], PointPosition, meshObject);
			}
		}
	}
}



[numthreads(32,32,1)]
void RayTrace(uint3 id : SV_DispatchThreadID)
{
	uint width, height;
	_RayTracer.GetDimensions(width, height);
	
	Hit hit;
	hit.normal = 0;
	hit.position = 0;
	hit.distance = 1500;
	hit.color = 0;
	//This is a ray for each pixel and in the pixel's center.
	//So id.xy is this pixel, then offsetted to center, then divided by the width and height to get said center.
	//Then range is shifted via 2 - 1.
	float2 pixel = ((id.xy + float2(0.5, 0.5)) / float2(width, height)) * 2 - 1; //Note in HLSL this vector v - scalar is applied to each element in v.
	Ray ray = CreateCameraRay(pixel);
	float4 result = 0;

	// Trace single triangle
	/*
	float3 v0 = float3(-150, 0, -150);
	float3 v1 = float3(150, 0, -150);
	float3 v2 = float3(0, 150 * sqrt(2), -150);
	float t, u, v;

	*/
	uint numOfStructs, sizeOfStrides; 
	_MeshObjects.GetDimensions(numOfStructs, sizeOfStrides);
	for (int k = 0; k < numOfStructs; k++)
	{
		MeshObject meshObject = _MeshObjects[k];
		TraceMesh(ray, hit, meshObject);
	}
	/*
	if (TriangleTrace(ray, v0, v1, v2, t, u, v))
	{
		if (t > 0 && t < hit.distance)
		{
			hit.distance = t;
			hit.position = ray.o + t * ray.d;
			hit.normal = normalize(cross(v1 - v0, v2 - v0));
			hit.color = 1.00f;

		}
	}
	*/
	/*
	for (int k = 0; k < 80; k++)
	{

		Trace(ray, hit);
		float3 r = Reflection(ray, hit);
		result += float4(hit.color, 1);



		
		if (!any(ray.energy))
			break;

	}
	*/

	_RayTracer[id.xy] = float4(hit.color, 1);


}

