// Each #kernel tells which function to compile; you can have many kernels
#pragma kernel SVGFKernel
#pragma kernel StoreToPreviousBuffer
#pragma kernel Atorus

// Create a RenderTexture with enableRandomWrite flag and set it
// with cs.SetTexture
Texture2D<float4> _CameraMotionVectorsTexture;
Texture2D<float4> _UnigmaGlobalIllumination;

RWTexture2D<float4> _UnigmaDenoisedGlobalIllumination;
RWTexture2D<float4> _UnigmaAlbedo;
RWTexture2D<float4> _UnigmaNormal;
RWTexture2D<float4> _UnigmaMotionID;

//Temporal buffers.
RWTexture2D<float4> _UnigmaDenoisedGlobalIlluminationTemporal;
RWTexture2D<float4> _UnigmaAlbedoTemporal;
RWTexture2D<float4> _UnigmaNormalTemporal;
RWTexture2D<float4> _UnigmaMotionIDTemporal;

struct SVGF
{
	float history;
	float2 moments;
};

RWStructuredBuffer<SVGF> _SVGFBuffer;


float _PLANE_DISTANCE_THRESHOLD = 0.01;
float _NORMAL_DISTANCE_THRESHOLD = 0.01;
int _StepSize = 1;

float luminance(float3 color)
{
	return (color.r * 0.3) + (color.g * 0.59) + (color.b * 0.11);
}

bool CheckNormalSimilarity(float3 currentNormal, float3 prevNormal)
{
	if (pow(abs(dot(currentNormal, prevNormal)), 2) > 0.999999)
		return false;
	else
		return true;
}

bool CheckPlane(float3 currentPos, float3 prevPos, float3 currentNormal)
{
	float3 toCurrent = currentPos - prevPos;
	float distToPlane = abs(dot(toCurrent, currentNormal));

	return distToPlane > 0.000000000000000000000001;
	
}

bool CheckReprojection(float2 UV, float2 prevUV)
{
	bool planeCheck = CheckPlane(_UnigmaMotionID[UV].xyz, _UnigmaMotionIDTemporal[prevUV].xyz, _UnigmaNormal[UV].xyz);
	
	bool normalCheck = CheckNormalSimilarity(_UnigmaNormal[UV].xyz, _UnigmaNormalTemporal[prevUV].xyz);
	
	return normalCheck && planeCheck;
}

bool IsNaN(float x)
{
	uint exponent = (asuint(x) & 0x7f800000) >> 23;
	uint mantissa = (asuint(x)) & 0x7fffff;
	return exponent == 0xff && mantissa != 0;
}

[numthreads(8,8,1)]
void SVGFKernel(uint3 id : SV_DispatchThreadID)
{
	uint dimensionsWidth, dimensionsHeight;
	
	_CameraMotionVectorsTexture.GetDimensions(dimensionsWidth, dimensionsHeight);
	uint2 dim = uint2(dimensionsWidth, dimensionsHeight);
	
	if (id.x >= dim.x || id.y >= dim.y)
		return;

	//Get current sample.
	float4 currentSample = _UnigmaGlobalIllumination[id.xy];

	//Get motion vectors
	float4 motionVector = _CameraMotionVectorsTexture[id.xy];
	float2 UV = ((id.xy + float2(0.5, 0.5)) / float2(dim.x, dim.y)) * 2 - 1;
	float2 invPrevUV = UV - motionVector.xy;
	
	float2 previousFrameIndex = ((invPrevUV * dim.xy + dim.xy) / 2) - 0.5f;
	int previousFrameIndedFlatten = previousFrameIndex.x + previousFrameIndex.y * dim.x;
	
	float4 output = currentSample;
	
	float historyLength = 1.0f;
	int flattenIndex = id.x + id.y * dim.x;
	float variance = 1.0;

	if (CheckReprojection(id.xy, previousFrameIndex))
	{
		float4 prevSample = _UnigmaDenoisedGlobalIlluminationTemporal[previousFrameIndex];
		historyLength = _SVGFBuffer[previousFrameIndedFlatten].history += 1;
		
		float alpha = 1.0f / historyLength;

		float2 moments = 0;
		moments.r = luminance(currentSample.xyz);
		moments.g = moments.r * moments.r;

		float2 historyMoment = _SVGFBuffer[previousFrameIndedFlatten].moments;
		
		
		moments = lerp(historyMoment, moments, alpha);
		variance = max(0.0f, moments.g - moments.r * moments.r);
		
		output = lerp(prevSample, currentSample, alpha);
		
		_SVGFBuffer[flattenIndex].history = historyLength;
		_SVGFBuffer[previousFrameIndedFlatten].moments = moments;
	}
	else
	{
		_SVGFBuffer[previousFrameIndedFlatten].history = 0;
	}

	_UnigmaDenoisedGlobalIllumination[id.xy] = output;//_UnigmaGlobalIllumination[id.xy];// + _UnigmaDenoisedGlobalIlluminationTemporal[id.xy] *0.5;
	
}

[numthreads(8, 8, 1)]
void StoreToPreviousBuffer(uint3 id : SV_DispatchThreadID)
{
    _UnigmaAlbedoTemporal[id.xy] = _UnigmaAlbedo[id.xy];
	_UnigmaNormalTemporal[id.xy] = _UnigmaNormal[id.xy];
	_UnigmaMotionIDTemporal[id.xy] = _UnigmaMotionID[id.xy];
	_UnigmaDenoisedGlobalIlluminationTemporal[id.xy] = _UnigmaDenoisedGlobalIllumination[id.xy];
}

[numthreads(8, 8, 1)]
void Atorus(uint3 id : SV_DispatchThreadID)
{
	uint dimensionsWidth, dimensionsHeight;

	_CameraMotionVectorsTexture.GetDimensions(dimensionsWidth, dimensionsHeight);
	uint2 dim = uint2(dimensionsWidth, dimensionsHeight);

	if (id.x >= dim.x || id.y >= dim.y)
		return;

	//Get current sample.
	float4 currentSample = _UnigmaGlobalIllumination[id.xy];

	//Get motion vectors
	float4 motionVector = _CameraMotionVectorsTexture[id.xy];
	float2 UV = ((id.xy + float2(0.5, 0.5)) / float2(dim.x, dim.y)) * 2 - 1;
	float2 invPrevUV = UV - motionVector.xy;

	float2 previousFrameIndex = ((invPrevUV * dim.xy + dim.xy) / 2) - 0.5f;
	int previousFrameIndedFlatten = previousFrameIndex.x + previousFrameIndex.y * dim.x;

	float4 output = currentSample;
	
	//A torus filter.
	float sumWeights = 1.0;
	float4 sum = output;
	//float sumVariance = variance;

	int _KernelSize = 3;
	int stepSize = 3;

	for (int yy = -_KernelSize; yy <= _KernelSize; yy++)
	{
		for (int xx = -_KernelSize; xx <= _KernelSize; xx++)
		{
			float2 offset = float2(xx, yy);
			float2 sampleUV = id.xy + offset * stepSize;

			if (sampleUV.x < 0 || sampleUV.x >= dim.x || sampleUV.y < 0 || sampleUV.y >= dim.y)
				continue;
		}
	}

}
